{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "\n",
    "Random forests are one of the most popular models in modern day data science and machine learning.\n",
    "The combine decision trees with two new ideas:\n",
    "\n",
    "- Random sampling of data \n",
    "- Random sampling of features\n",
    "\n",
    "Let's talk about each of these in turn.\n",
    "\n",
    "## Random sampling of data\n",
    "\n",
    "As we've seen, decision trees tend to overfit if we don't limit how large they can grow.\n",
    "We can *regularize* the tree by applying a penalty to trees based on their size and fit.\n",
    "Or we can be low tech and just blanket restrict how large we'll allow trees to get, regardless of fit.\n",
    "\n",
    "There is another way to deal with the overfitting problem that may surprise you - don't deal with it!\n",
    "Instead of trying to make a single perfect tree, this approach is to make lots of imperfect trees, a **forest**.\n",
    "It turns out that if we average the predictions of a lot of imperfect trees, we can get a prediction that is as good, or better, than a single perfect tree.\n",
    "But there's a catch: this only works if the imperfect trees are *different* from each other.\n",
    "Obviously, if they were all the same, then averaging them would give the same prediction as any one of them.\n",
    "\n",
    "Random sampling of the data is one way we can ensure the trees in our forest are different from each other.\n",
    "Every time we want to make a tree, we sample just part of our data and build a tree with that.\n",
    "Because every sample is random, our trees will be different from each other.\n",
    "This kind of sampling is called **bootstrapping**, which is just a funny way of saying that we are sampling *with replacement*.\n",
    "An example of bootstrapping 10 cards from a deck of cards would be to shuffle the deck, draw 10 cards off the top, \"use\" them, and then put them back in the deck (\"replace\" them).\n",
    "\n",
    "If we bootstrap a forest of trees, and then average (or combine) their predictions, this is called **bootstrap aggregating**, or **bagging** for short.\n",
    "Don't worry if you find these names really strange, because you're not alone!\n",
    "As an example of aggregation, suppose I have 100 trees in my forest, and I ask all of them to predict if someone has a disease or not (a binary classification task).\n",
    "If 51 of them say `Positive` and 49 say `Negative`, then the majority are `Positive` and that is the prediction of the forest as a whole.\n",
    "Another example would be a regression task, where each tree in the forest predicts the fuel economy (mpg) of a car based on its engine, weight, etc.\n",
    "In that case, each regression tree in the forest would predict a numeric mpg, and these would be averaged to get the prediction of the forest as a whole.\n",
    "\n",
    "## Bagging example\n",
    "\n",
    "Bagging by itself is a data science technique, so we can try it out by itself before moving on to random forests.\n",
    "\n",
    "If we were to do bagging from scratch, you might imagine we'd have a loop where each time we sampled some rows from a data frame, built a classifier, and then saved the classifier in a list.\n",
    "Then when we wanted to classify something, we'd run it through each classifier in the list to get the predictions, and then we'd average those to get the final prediction.\n",
    "\n",
    "Fortunately for us, `sklearn` takes care of all of those steps for us.\n",
    "All we need to do is wrap the normal `DecisionTreeClassifier` in a `BaggingClassifier`.\n",
    "\n",
    "### Load data\n",
    "\n",
    "Let's look at some breast cancer diagnostic [data](https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset), which consists of the following variables as mean, standard error, and \"worst\" (mean of three largest variables) collected by digital imagery of a biopsy.\n",
    "\n",
    "| Variable | Type | Description |\n",
    "|:-------|:-------|:-------|\n",
    "|radius | Ratio | mean of distances from center to points on the perimeter|\n",
    "|texture | Ratio | standard deviation of gray-scale values|\n",
    "|perimeter | Ratio | perimeter of cancer|\n",
    "|area | Ratio | area of cancer|\n",
    "|smoothness | Ratio | local variation in radius lengths|\n",
    "|compactness | Ratio |  perimeter^2 / area - 1.0|\n",
    "|concavity | Ratio |  severity of concave portions of the contour|\n",
    "|concave points | Ratio |  number of concave portions of the contour|\n",
    "|symmetry | Ratio | symmetry of cancer|\n",
    "|fractal dimension | Ratio | \"coastline approximation\" - 1|\n",
    "| class | Nominal (binary) | malignant (1) or benign (0)\n",
    "\n",
    "The goal is to predict the presence/absence of cancer.\n",
    "\n",
    "First, the imports:\n",
    "\n",
    "- `import pandas as pd`\n",
    "- `import sklearn.datasets as datasets`\n",
    "- `import sklearn.ensemble as ensemble`\n",
    "\n",
    "bag = BaggingClassifier(tree, n_estimators=100, max_samples=0.8,\n",
    "                        random_state=1)\n",
    "\n",
    "bag.fit(X, y)\n",
    "visualize_classifier(bag, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.datasets as datasets\n",
    "import sklearn.ensemble as ensemble\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"7]_oG^Y0XV,0(!d:E.}0\">pd</variable><variable id=\"=l55S6$w5{IDU+4ID(5M\">datasets</variable><variable id=\"YrOLY99XD^WJhuTK)IFx\">ensemble</variable></variables><block type=\"importAs\" id=\"MaTZ%BMEZU[L}(_VL)3f\" x=\"51\" y=\"48\"><field name=\"libraryName\">pandas</field><field name=\"libraryAlias\" id=\"7]_oG^Y0XV,0(!d:E.}0\">pd</field><next><block type=\"importAs\" id=\"PL5chXruGcet8N2(%vB@\"><field name=\"libraryName\">sklearn.datasets</field><field name=\"libraryAlias\" id=\"=l55S6$w5{IDU+4ID(5M\">datasets</field><next><block type=\"importAs\" id=\"aH_~S~W~@4D,8tXvn_s6\"><field name=\"libraryName\">sklearn.ensemble</field><field name=\"libraryAlias\" id=\"YrOLY99XD^WJhuTK)IFx\">ensemble</field></block></next></block></next></block></xml>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The breast cancer data is built into `sklearn`, so we need to grab it an put it in a variable:\n",
    "\n",
    "- Create variable `cancer_sklearn`\n",
    "- Set it to `with datasets do load_breast_cancer using`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_sklearn = datasets.load_breast_cancer()\n",
    "\n",
    "#<xml xmlns=\"https://developers.google.com/blockly/xml\"><variables><variable id=\"etU=(k#nJyVsPHL@^Jv.\">cancer_sklearn</variable><variable id=\"=l55S6$w5{IDU+4ID(5M\">datasets</variable></variables><block type=\"variables_set\" id=\"Jy]Veqr#Nz^tri-F}]~|\" x=\"50\" y=\"210\"><field name=\"VAR\" id=\"etU=(k#nJyVsPHL@^Jv.\">cancer_sklearn</field><value name=\"VALUE\"><block type=\"varDoMethod\" id=\"FK0hhKS}if`R/ncgG?)]\"><field name=\"VAR\" id=\"=l55S6$w5{IDU+4ID(5M\">datasets</field><field name=\"MEMBER\">load_breast_cancer</field><data>datasets:load_breast_cancer</data></block></value></block></xml>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
