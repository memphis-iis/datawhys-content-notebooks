{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "\n",
    "Random forests are one of the most popular models in modern day data science and machine learning.\n",
    "The combine decision trees with two new ideas:\n",
    "\n",
    "- Random sampling of data \n",
    "- Random sampling of features\n",
    "\n",
    "Let's talk about each of these in turn.\n",
    "\n",
    "## Random sampling of data\n",
    "\n",
    "As we've seen, decision trees tend to overfit when we don't restrict how large they are.\n",
    "We can *regularize* the tree by applying a penalty to trees based on their size and fit.\n",
    "Or we can be low tech and just blanket restrict how large we'll allow trees to be.\n",
    "\n",
    "There is another way to deal with the overfitting problem that may surprise you - don't deal with it!\n",
    "Instead of trying to make a single perfect tree, this approach is to make lots of imperfect trees, a **forest**.\n",
    "It turns out that if we average the predictions of a lot of imperfect trees, we can get a prediction that is as good, or better, than a single perfect tree.\n",
    "But there's a catch: this only works if the imperfect trees are *different* from each other.\n",
    "Obviously, if they were all the same, then averaging them would give the same prediction as any one of them.\n",
    "\n",
    "Random sampling of the data is one way we can ensure the trees in our forest are different from each other.\n",
    "Every time we want to make a tree, we sample just part of our data and build a tree with that.\n",
    "Because every sample is random, our trees will be different from each other.\n",
    "This kind of sampling is called **bootstrapping**, which is just a funny way of saying that we are sampling *with replacement*.\n",
    "An example of bootstrapping 10 cards from a deck of cards would be to shuffle the deck, draw 10 cards off the top, \"use\" them, and then put them back in the deck (\"replace\" them).\n",
    "\n",
    "If we bootstrap a forest of trees, and then average (or combine) their predictions, this is called **bootstrap aggregating** or **bagging** for short.\n",
    "Don't worry if you find these names really strange, because you're not alone!\n",
    "As an example of aggregation, suppose I have 100 trees in my forest, and I ask all of them to predict if someone has a disease or not (a binary classification task).\n",
    "If 51 of them say `Positive` and 49 say `Negative`, then the majority are `Positive` and that is the prediction of the forest as a whole.\n",
    "Another example would be a regression task, where each tree in the forest predicts the fuel economy (mpg) of a car based on its engine, weight, etc.\n",
    "In that case, each regression tree in the forest would predict a numeric mpg, and these would be averaged to get the prediction of the forest as a whole.\n",
    "\n",
    "## Bagging example\n",
    "\n",
    "Bagging by itself is a data science technique, so we can try it out by itself before moving on to random forests.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
