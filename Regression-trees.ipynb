{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous notebook you learned about decision trees which partition\n",
    "a data set based on criteria of different variables (features) that can\n",
    "be categorical and/or numeric.\n",
    "In this notebook we will see how the\n",
    "decision trees can be used to make predictions.\n",
    "This method is known as\n",
    "*regression trees*.\n",
    "\n",
    "# Basics of Regression Trees\n",
    "\n",
    "A regression tree is a non-parametric model that is used to predict\n",
    "response variables.\n",
    "They are a simple and interpretable alternative to\n",
    "multiple regression, which also uses features to predict a response\n",
    "assuming the relationship between response and features is linear.\n",
    "Regression trees are particularly useful when the relationship between\n",
    "response and features may be non-linear and difficult to specify.\n",
    "The\n",
    "figure below is an example of a regression tree.\n",
    "In this model, baseball\n",
    "players salaries are predicted based on how long they have been playing\n",
    "and the number of hits the player had in the previous season.\n",
    "Because\n",
    "the salaries of some baseball players can be much larger than the\n",
    "majority of the players (i.e.\n",
    "the salaries have outliers), we use a\n",
    "transformation and look at the log of the salaries.\n",
    "\n",
    "![](HittersPrune){width=\"12cm\"}\n",
    "\n",
    "In this tree, the first partition is based on whether the player has\n",
    "been playing less than 4.5 years (left branch) or greater than or equal\n",
    "to 4.5 years (right branch).\n",
    "For players who have been playing less than\n",
    "4.5 years, the number of hits is not useful in predicting their salary.\n",
    "Their salary is predicted by averaging all the salaries of players with\n",
    "years &lt; 4.5.\n",
    "This number is shown at the leaf of this branch and is\n",
    "5.107.\n",
    "Remember this is the log of the salary (in thousands of dollars)\n",
    "and so the predicted salary is $1000*e^{5.107} = \\$ 165,174$.\n",
    "\n",
    "For the players that have been playing for longer than 4.5 years, the\n",
    "variable *Hits* further distinguishes the predicted salary.\n",
    "For\n",
    "those with hits below 117.5, the predicted log salary, 5.998, is found\n",
    "as the average log salary of all players who have both $ Years \\ge 4.5$\n",
    "and $Hits < 117.5$.\n",
    "\n",
    "![](regPlot){width=\"12cm\"}\n",
    "\n",
    "The regression tree can be visualized as in the plot in Figure 2.\n",
    "The\n",
    "region *R1* corresponds to all players who have been playing less\n",
    "than 4.5 years.\n",
    "The average of the log salaries in region R1is the\n",
    "predicted value shown in the tree in Figure 1, 5.107.\n",
    "The three regions\n",
    "can be summarized as\n",
    "\n",
    "-   R1: X | Years &lt;4.5\n",
    "\n",
    "-   R2: X | Years $\\ge$ 4.5, Hits &lt; 117.5\n",
    "\n",
    "-   R3: X | Years $\\ge$ 4.5, Hits $\\ge$ 117.5\n",
    "\n",
    "# How are regression trees made?\n",
    "\n",
    "The algorithm that creates the tree partitions the set of features into\n",
    "$J$ distinct and non-overlapping regions, $R_1, R_2, \\ldots, R_J$.\n",
    "The\n",
    "predicted response in region $R_i$ is then the mean (arithmetic average)\n",
    "of the responses in that region.\n",
    "The regions are defined to be\n",
    "rectangles (or higher-dimension boxes) for simplicity.\n",
    "The regions are\n",
    "chosen to minimize the sum of the squared differences between each\n",
    "observed response and the predicted response.\n",
    "It is not computationally\n",
    "possible to look at all possible partitions, so the regression tree is\n",
    "constructed using *recursive binary splitting*, which means that at\n",
    "each split, the tree branches into two parts choosing the best split (in\n",
    "terms of the sum of squared differences).\n",
    "\n",
    "# Pruning\n",
    "\n",
    "The tree shown in Figure 1 is actually derived from another tree by\n",
    "*pruning*.\n",
    "It is a tree that has been pruned to have only three\n",
    "nodes.\n",
    "A bigger tree is shown in the figure below.\n",
    "This tree has eight\n",
    "nodes rather than three and the prediction of salary is seen to be a bit\n",
    "more complex than the previous tree.\n",
    "\n",
    "![](treefit){width=\"12cm\"}\n",
    "\n",
    "It is often a good idea to start with a big tree and use some systematic\n",
    "methods to prune the tree to an acceptable or optimal level.\n",
    "There are\n",
    "algorithms similar to the Lasso that can be used to find a good pruning\n",
    "(called a *subtree*) for our regression tree that penalizes the sum\n",
    "of squared errors for having more nodes.\n",
    "For example, if you have the\n",
    "number of nodes equal to the number of data points with one point per\n",
    "node, your sum of squared errors would be zero since the predicted value\n",
    "would equal the observed value for all nodes.\n",
    "But this would not be very\n",
    "good for prediction of a new data point.\n",
    "Ideally we would like to have\n",
    "enough nodes (leaves) so that the responses within each leaf are closely\n",
    "spaced and the regression surface is nearly constant.\n",
    "\n",
    "# Summary\n",
    "\n",
    "Some of the advantages of regression trees are summarized here.\n",
    "\n",
    "-   Making predictions is fast - you just look up the constants in the\n",
    "    tree.\n",
    "\n",
    "-   It is easy to see what variables are most important in making the\n",
    "    predictions.\n",
    "\n",
    "-   If some data is missing and we canâ€™t get all the way to a leaf, we\n",
    "    can still make a prediction by averaging all the leaves in the\n",
    "    subtree we can reach.\n",
    "\n",
    "-   The model works well for non-linear relationships and for linear\n",
    "    relationships.\n",
    "\n",
    "-   The trees can be built quickly using computer algorithms.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
