{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <b>Last Updated:</b> 9JUNE2020 </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Authors:__ Dale Bowman, PhD; Natasha A Sahr, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification problem involves the training of a _classifier_ to determine to which of several groups a new observation vector should be assigned. There are many different types of classifiers can be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between classification and clustering is simple. In clustering, the grouping in the dataset is unknown or latent and we are searching for these unknown patterns in the data. In classification, we have a dataset where the grouping is known and want to use that information to build a tool to classify a new object whose group is unknown. \n",
    "\n",
    "Clustering is an _unsupervised_ method since the correct classes are unknown. Classification is a _supervised_ method since the classes are known. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at two commonly used classifiers: __linear discriminant analysis__ (LDA) and $\\mathbf{k}$__-nearest neighbors__ (KNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have response variable $Y$ which can belong to one of $C$ different categories (classes). Associated with $Y$ is a set of features, $\\mathbf{X}$. For each of the $C$ categories there is associated a __prior probability__ of belonging to that class, denoted $\\pi_i$ for$i=1,\\dots,C$. If no information is known about the class probabilities, we can set $\\pi_1=\\pi_2=\\cdots=\\pi_C$. For each category of $Y$, there is an associated _density function_, $f_i(\\mathbf{x}) = P(\\mathbf{X} = \\mathbf{x}| Y=i)$. That is <$f_i(\\mathbf{x})$ is the probability that $Y$ is in category $i$ given the observed $\\mathbf{X}$. The probability $f_i(\\mathbf{x})$ will be relatively high if $Y$ is in class $i$ and relatively low if $Y$ is in another category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the probability that $Y$ is in class $k$ given the value of observed vector $\\mathbf{X}$ we use _Bayes Theorem_ which states that \n",
    "\n",
    "$$Pr(Y=k|\\mathbf{X}= \\mathbf{x}) = \\frac{\\pi_k f_k(\\mathbf{x})}{\\sum_{i=1}^C \\pi_i f_i(\\mathbf{x})}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign $Y$ to the class with the highest probability. The probability $Pr(Y=k|\\mathbf{X}= \\mathbf{x})$ is called a __posterior probability__. In general, we won’t know the value of the prior probabilities, $\\pi_i$’s, or the form of the density functions, $f_i(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When $p=1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA classifier can be illustrated when there is only one feature ($p=1$). For this case, LDA assumes a _normal_ (or Gaussian) distribution for $f_i(\\mathbf{x})$. The general equation for the normal density is \n",
    "\n",
    "$$f_i(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma_i^2}} \\exp \\left( \\frac{1}{2 \\sigma_i^2} (x-\\mu_i)^2 \\right).$$\n",
    "\n",
    "In the normal distribution, $\\mu_i$ is the __mean__ (measuring central tendency) and $\\sigma_i^2$ is the __variance__ (measuring dispersion). It is symmetric about the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LDA classifier makes a further assumption that the variances are equal across categories, i.e. $\\sigma_1^2=\\sigma_2^2=\\cdots=\\sigma_C^2=\\sigma^2$. If this assumption is not reasonable, a _quadratic discriminant analysis_ can be used. Using the normal model the posterior probability becomes, \n",
    "\n",
    "$$P(Y=k|X=x) = \\frac{ \\pi_k \\exp \\left(\\frac{1}{2\\sigma^2} (x-\\mu_k)^2\\right)}{\\sum_{i=1}^C \\pi_i \\exp \\left(\\frac{1}{2\\sigma^2} (x-\\mu_i)^2\\right)}$$\n",
    "\n",
    "A new observation with feature value $x_0$ is classified into the category for which this probability is the biggest. If we take the log of this equation and drop some common terms, this is equivalent to choosing to assign $x_0$ to the category for which $\\delta_k$ is largest, for \n",
    "\n",
    "$$\\delta_k(x) = x_0 \\frac{\\mu_k}{\\sigma^2} - \\frac{\\mu_k^2}{2\\sigma^2} + \\log(\\pi_k).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can illustrate the LDA classifier for the case where $K=2$ and $\\pi_1=\\pi_2=0.5$ in Figure 1 below. The <font color=\"red\"> red line is a normal distribution with $\\mu = - 1.25$ and $\\sigma^2 = 1$</font> and the <font color=\"blue\"> blue line is a normal distribution with $\\mu = 1.25$ and  $\\sigma^2 = 1$</font>. The black line ($x = 0$) shows the _decision boundary_ found using the LDA classifier. The response, $Y$, will be classified into: \n",
    "- <font color=\"red\"> the red group for values of $X < 0$</font>; and,\n",
    "- <font color=\"blue\"> blue group for values of $X > 0$</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 1__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <div class=\"img-box\">\n",
    "        <img src=\"images/lda-1.jpg\" alt=\"img1\" style=\"width:100%\" />\n",
    "    </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, in practice we don’t know the population mean or variance of the $C$ classes, so we estimate these parameters from the training data. We use the sample means within each category to estimate the $\\mu_i$’s and the sample variance $S^2$ using all the data to estimate the common variance $\\sigma^2$. We can estimate the prior probabilities using the proportions of responses in each category in our training data. For example, if we have 20 observations in category 1 and a total of 100 observations, we would estimate $\\pi_1$ as $\\frac{20}{100} = 0.2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the case where $p>2$, the LDA is constructed similarly using a multivariate normal distribution. This distribution assumes that each of the $p$ features in the observation vector, $X$, has a normal distribution and it takes into account any linear relationships between the features using the correlation between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have previously used the `iris.csv` dataset. The `iris.csv` dataset contains 5 variables:\n",
    "\n",
    "- `SepalLength`: the sepal length (cm)\n",
    "- `SepalWidth`: the sepal width (cm)\n",
    "- `PetalLength`: the petal length (cm)\n",
    "- `PetalWidth`: the petal width (cm)\n",
    "- `Species`: the flower species (cm)\n",
    "\n",
    "Import `pandas` as `pd`. Use the function `read_csv` in `pandas` to read in the `iris.csv` dataset and name it `dta_iris`. \n",
    "\n",
    "__Note__: The variable names are not found in the file and the file does not have an index.\n",
    "\n",
    "Print the first 5 observations to familiarize yourself with the data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth      Species\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_iris = pd.read_csv(\"datasets/iris.csv\", \n",
    "                       header=None,\n",
    "                       names=['SepalLength',\n",
    "                              'SepalWidth',\n",
    "                              'PetalLength',\n",
    "                              'PetalWidth',\n",
    "                              'Species'])\n",
    "\n",
    "dta_iris.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform LDA, import `numpy` as `np` and `pandas` as `pd`. We will need these libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the dataset is loaded into a dataframe object, the first step is to separate the dataset into features and corresponding labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the first 4 columns of `dta_iris` using the `iloc` function. These columns correspond to the features. Use the `values` function correctly format the dataframe into an array. Name the resulting object `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dta_iris.iloc[:, 0:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the last column of `dta_iris` using the `iloc` function. This column corresponds to the labels. Use the `values` function correctly format the dataframe into an array. Name the resulting object `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dta_iris.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to split our features and labels into a training set (`X_train`, `Y_train`) and a testing set (`X_test`, `Y_test`). To do this, we need to  from `sklean.model_selection` import the `train_test_split` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `train_test_split` function with the arguments\n",
    "- `X`: the features in an array\n",
    "- `Y`: the labels in an array\n",
    "- `test_size=0.2`: the proportion of the dataset to include in the test split\n",
    "The resulting object will have 4 names: `X_train, X_test, Y_train, Y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale the features so `SepalWidth`, `SepalLength`, `PetalLength`, and `PetalWidth` are on the same scale. To do this, we need to from `sklearn.preprocessing` import the `StandardScaler` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `SepalWidth`, `SepalLength`, `PetalLength`, and `PetalWidth` are in `X_train` and `X_test`, we will transform both. \n",
    "\n",
    "First, use the function `fit_transform` with the object `X_train` on `StandardScaler()`. Rename the object `X_train1`. \n",
    "\n",
    "Next, use the function `fit_transform` with the object `X_test` on `StandardScaler()`. Rename the object `X_test1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = StandardScaler().fit_transform(X_train)\n",
    "X_test1 = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whew! There is a lot of data preparation required prior to training a classifier. Thankfully, LDA implentation requires only four lines of code using `scikit-learn`. \n",
    "\n",
    "1. From `sklearn.discriminant_analysis` import the function `LinearDiscriminantAnalysis` named as `LDA`.\n",
    "2. Use the function `LDA` with the argument `n_components=1` and name it `lda_iris`. The parameter `n_components` refers to the number of linear discriminates we want to retreive. In setting this argument to `1`, we are checking the performance of a classifier with a single linear discriminant.\n",
    "3. Use the function `fit_transform` with arguments `X_train1` and `Y_train1`on the `lda_iris` object and name it `lda_iris_fit`.\n",
    "4. Use the function `transfor` with argument `X_test1` on the `lda_iris` object and name it `lda_iris_transform`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "lda_iris = LDA(n_components=1)\n",
    "lda_iris_fit = lda_iris.fit_transform(X_train1, Y_train)\n",
    "lda_iris_transform = lda_iris.transform(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lda_iris_fit` object contains the training linear discriminants. The `lda_iris_transform` object contains the testing linear discriminants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to use the LDA to predict classes, hence `classification`. Use the function `predict` with the argument `X_test1` on the object `lda_iris` and name it `lda_pred_iris_labels`. This named object will contain the predicted labels for the features in the test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred_iris_labels = lda_iris.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, we may want to evaluate the performance by extracting the predicted probabilities that the observation (row of features) would fall into each class. To get this matrix, use the function `predict_proba` with argument `X_test1` on the object `lda_iris` and name it `lda_pred_iris_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred_iris_prob = lda_iris.predict_proba(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have performed all steps to train and predict classes with an LDA classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $k$-nearest neighbor (KNN) method of classification is also based on the posterior probabilities of the response being in a category given the observed vectors. The difference is in how this probability is estimated. For a given value of $K$ and a new observation vector, $x_0$, first the $K$ observation vectors in the data set that are nearest to $x_0$ are found. Out of this set of $k$ vectors, the posterior probability of class $j$ is found by counting the number of the $K$ nearest neighbors that are in class $j$ divided by $K$. The new observation vector, $x_0$, is then classified into the class with the highest posterior probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The choice of $K$ has a great impact on the KNN classifier. When $K$ is low, the classifier tends to be overly flexible, while for $K$ too high the classifier becomes less flexible and will make more mistakes. If we use a part of the data to train the classifier (_training data set_) and then test it on the rest of the data (_test data set_), then for $K$ too low, you will get low error rates on the training set but you may get very high error rates on the test set. This implies the classifier has been _over fit_. On the other hand if $K$ is too high the error rate on the training set will be too low and will not be useful for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-Nearest Neighbor Programming Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same `iris.csv` dataset as in the LDA example. Recall, data has already been pre-processed for use. We have: \n",
    "\n",
    " - the training set: `X_train1` the features, `Y_train` the labels\n",
    " - the testing set: `X_test1` the features, `Y_test` the labels\n",
    " \n",
    "To perform the KNN classifier, we need to import `KNeighborsClassifier` from `sklearn.neighbors` as `KNNclass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNNclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function `KNNclass` with the argument `n_neighbors=5` and assign the object to `knnclass_iris`. The choice of the number of neighbors will depend on classifier tuning. For now, assume we will use 5 neighbors as it is one of the most commonly used values for the KNN algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass_iris = KNNclass(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the KNN algorithm using the function `fit` with arguments `X_train1` and `Y_train` on `knnclass_iris`. Name the object `knnclass_iris_fit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass_iris_fit = knnclass_iris.fit(X_train1, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the predicted classes from the KNN algorithm, use the function `predict` with argument `X_test1` on `knnclass_iris` and name the resulting array `knnclass_pred_iris_labels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass_pred_iris_labels = knnclass_iris.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have performed all steps to train and predict classes with an KNN classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity, consider a classifier where the response variable has only two classes, say positive (1) and negative (0). A _confusion matrix_ is a tool to evaluate the predictive value of the classifier. The table below is an example of a confusion matrix for a two category classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 2__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <div class=\"img-box\">\n",
    "        <img src=\"images/confusionMatrixSimple.png\" alt=\"img1\" style=\"width:100%\" />\n",
    "    </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Source:__ https://justmachinelearning.com/2019/09/26/simple-guide-to-the-confusion-matrix/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A prediction is a true positive (TP) if the actual value was positive and the classifier predicted it to be positive. A prediction is a true negative (TN) if the actual value was negative and the classifier predicted it to be negative. TP and TN are correct predictions and should be large for a _good classifier_. \n",
    "\n",
    "A prediction is a false positive (FP) if the actual response was negative and the predicted response was positive. A prediction is a false negative (FN) if the actual response was positive and the classifier predicted it to be negative. FP and FN are errors and should be small for a _good classifier_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a medical setting for evaluating diagnostic tests. TP is the number of people that have the disease and the test correctly showed that they have the disease. TN is the number of people that don’t have the disease and the test correctly says they don’t. FP is the number of people who do not have the disease but the test incorrectly predicts that they do and FN is the number of people who do have the disease but the test predicts they don’t."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some additional measures used to assess the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _sensitivity_ also called recall is defined as the ratio of true positive to total number of actual positives, $\\frac{TP}{TP+FN}$. The sensitivity will be between 0 and 1. The better the classifier, the larger the sensitivitiy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _specificity_ also called precision is a similar measure for the negative response. It is the ratio of true negative to the total number of actual negatives, $\\frac{TN}{TN+FP}$. The specificity is also between 0 and 1. The better the classifer, the larger the specificity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A measure of the error that is often used is the _false discovery rate_ (FDR). The FDR measures how many of the actual negative responses were predicted as positive by the classifier, $FDR = \\frac{FP}{FP+TN} = 1 - \\text{specificity}$. The better the classifier, the smaller the FDR. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to construct confusion matrices for situations where there are more than two classes but the specificity, sensitivity and FDR are defined differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An expanded graphic is in Figure 3. Can you spot the metric missing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 3__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <div class=\"img-box\">\n",
    "        <img src=\"images/confusionMatrix.jpg\" alt=\"img1\" style=\"width:100%\" />\n",
    "    </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Source:__ https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Programming Example cont."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remeber our LDA programming example on the `iris.csv` dataset. We now want to evaluate the performance of the classifier for our test dataset. Our observed labels were called `Y_test` and our predicted labels were called `lda_pred_iris_labels`. \n",
    "\n",
    "We first need to import `confusion_matrix`, `classification_report`, and `accuracy_score` from `sklearn.metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the confusion matrix, use the function `confusion_matrix` with the arguments `Y_test` and `lda_pred_iris_labels`. Name the object `lda_iris_cm`. Print the confusion matrix `lda_iris_cm` using the `print` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "lda_iris_cm = confusion_matrix(Y_test, lda_pred_iris_labels)\n",
    "print(lda_iris_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the accuracy, use the function `accuracy_score` with the arguments `Y_test` and `lda_pred_iris_labels`. Name the object `lda_iris_acc`. Print the confusion matrix `lda_iris_acc` using the `print` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "lda_iris_acc = accuracy_score(Y_test, lda_pred_iris_labels)\n",
    "print(lda_iris_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the precision and recall for each of the classes, use the function `classification_report` with the arguments `Y_test` and `lda_pred_iris_labels`. Name the object `lda_iris_met`. Print the confusion matrix `lda_iris_met` using the `print` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      0.80      0.89        10\n",
      " Iris-virginica       0.82      1.00      0.90         9\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.93      0.93        30\n",
      "   weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lda_iris_met = classification_report(Y_test, lda_pred_iris_labels)\n",
    "print(lda_iris_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-Nearest Neighbor Programming Example cont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also evaluate the performance of our KNN classifier. Our observed labels were called `Y_test` and our predicted labels were called `knnclass_pred_iris_labels`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the confusion matrix as done previously with the function `confusion_matrix`. Name the confusion matrix for the KNN classifier as `knnclass_iris_cm`. Print the confusion matrix with the `print` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0  9]]\n"
     ]
    }
   ],
   "source": [
    "knnclass_iris_cm = confusion_matrix(Y_test, knnclass_pred_iris_labels)\n",
    "print(knnclass_iris_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the classification report as done previously with the function `classification_report`. Name the classification report for the KNN classifier as `knnclass_iris_met`. Print the classification report with the `print` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        11\n",
      "Iris-versicolor       1.00      0.80      0.89        10\n",
      " Iris-virginica       0.82      1.00      0.90         9\n",
      "\n",
      "       accuracy                           0.93        30\n",
      "      macro avg       0.94      0.93      0.93        30\n",
      "   weighted avg       0.95      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knnclass_iris_met = classification_report(Y_test, knnclass_pred_iris_labels)\n",
    "print(knnclass_iris_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The __ROC curve__ is a graphical tool to examine the errors of a classifier. ROC stands for receiver operating characteristics, a term from communications theory. Figure 4 below shows a typical ROC curve for a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Figure 4__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body>\n",
    "    <div class=\"img-box\">\n",
    "        <img src=\"images/ROC-1.jpg\" alt=\"img1\" style=\"width:100%\" />\n",
    "    </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ROC curve has the sensitivity on the vertical axis (y-axis) and 1-specificity (FDR) on the horizontal axis (x-axis). The ideal ROC curve hugs the top left corner which corresponds to a high true positive rate and a low false positive rate. The forty-five degree line that goes from bottom left (0,0) to upper right (1,1) shown as a black dotted line in the plot is considered to be a classifier that is no better than guessing i.e. the posterior probabilities are both 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single number summary of the ROC curve is the _AUC_ which stands for area under the (ROC) curve. The larger the AUC the better the classifier has done. The forty-five degree line has an AUC of 0.50 so a good classifier will have AUC higher than random guessing. For the ROC curve in Figure 4 the AUC is 0.8342. This is a moderately good classifier, certainly better than random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to work through a complete example using a new dataset. Refer to the previous sections for full instructions if you need assistance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The `binary.csv` dataset contains 4 variables:\n",
    "\n",
    "- `admit`: the admittance status (0=not admitted, 1=admitted)\n",
    "- `gre`: the student's GRE score\n",
    "- `gpa`: the student's GPA\n",
    "- `rank`: rank of the institution (1=highest to 4=lowest prestige)\n",
    "\n",
    "Use the function `read_csv` in `pandas` to read in the `binary.csv` dataset and name it `dta_admit`. \n",
    "\n",
    "__Note__: The variable names are found in the file and the file does not have an index.\n",
    "\n",
    "Print the first 5 observations to familiarize yourself with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dta_admit = pd.read_csv(\"datasets/binary.csv\")\n",
    "dta_admit.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to process the data. First thing it to split the data into features and labels. The labels are in the first column, named `admit`. The features are in the other three columns. Create `X` and `Y` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = dta_admit.iloc[:, 0].values\n",
    "X = dta_admit.iloc[:, 1:4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and testing data. Obtain four objects: `X_train`, `X_test`, `Y_train`, `Y_test`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the features. Obtain two objects: `X_train1`, `X_test1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1 = StandardScaler().fit_transform(X_train)\n",
    "X_test1 = StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform LDA. There will be three lines of code:\n",
    "1. Use the `LDA` function. Name the object `lda_admit`. \n",
    "2. Use the `fit_transform` function. Name the object `lda_admit_fit`.\n",
    "3. Use the `predict` function. Name the object `lda_pred_admit_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_admit = LDA(n_components=1)\n",
    "lda_admit_fit = lda_admit.fit_transform(X_train1, Y_train)\n",
    "lda_pred_admit_labels = lda_admit.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform KNN classification. There will be three lines of code:\n",
    "1. Use the `KNNclass` function. Name the object `knnclass_admit`. \n",
    "2. Use the `fit_transform` function. Name the object `knnclass_admit_fit`.\n",
    "3. Use the `predict` function. Name the object `knnclass_pred_admit_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass_admit = KNNclass(n_neighbors=5)\n",
    "knnclass_admit_fit = knnclass_admit.fit(X_train1, Y_train)\n",
    "knnclass_pred_admit_labels = knnclass_admit.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now interested in evaluating the ROC and AUC. To do that, import `roc_curve` and `roc_auc_score` from `sklearn.metrics`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FOR LDA__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `roc_curve` function with the arguments `Y_test` and `lda_pred_admit_labels`. Name the object `fpr_lda, tpr_lda, thresholds_lda`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_lda, tpr_lda, thresholds_lda = roc_curve(Y_test, lda_pred_admit_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_proba` function on `lda_admit` with argument `X_test1`. Name the object  `lda_pred_admit_proba`. Select the probabilities for the positive outcome only using `[:,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred_admit_proba = lda_admit.predict_proba(X_test1)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `roc_auc_score` function with the arguments `Y_test` and `lda_pred_admit_proba`. Name the object `auc_lda`. Use the function `print` to show `auc_lda`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6991210277214335\n"
     ]
    }
   ],
   "source": [
    "auc_lda = roc_auc_score(Y_test, lda_pred_admit_proba)\n",
    "print(auc_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is approximately 0.70 for the LDA performed on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__FOR LDA__:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the curve, we plot `fpr_lda` on the x-axis and `tpr_lda` on the y_axis. First, import `plotly.graph_objects` as `go`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `roc_curve` function with the arguments `Y_test` and `knnclass_pred_admit_labels`. Name the object `fpr_knnclass, tpr_knnclass, thresholds_knnclass`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_knnclass, tpr_knnclass, thresholds_knnclass = roc_curve(Y_test, knnclass_pred_admit_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `predict_proba` function on `knnclass_admit` with argument `X_test1`. Name the object  `knnclass_pred_admit_proba`. Select the probabilities for the positive outcome only using `[:,1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnclass_pred_admit_proba = knnclass_admit.predict_proba(X_test1)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `roc_auc_score` function with the arguments `Y_test` and `knnclass_pred_admit_proba`. Name the object `auc_knnclass`. Use the function `print` to show `auc_knnclass`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5341446923597025\n"
     ]
    }
   ],
   "source": [
    "auc_knnclass = roc_auc_score(Y_test, knnclass_pred_admit_proba)\n",
    "print(auc_knnclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC is approximately 0.53 for the KNN classification performed on this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ROC Curves__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the ROC curves for random guessing, LDA, and KNN classification on one plot, use the code below:\n",
    "\n",
    "<blockquote><tt>\n",
    "<pre>import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr_lda, \n",
    "                         y=tpr_lda, \n",
    "                         name='LDA',\n",
    "                         line=dict(color='royalblue'))) \n",
    "fig.add_trace(go.Scatter(x=fpr_knnclass, \n",
    "                         y=tpr_knnclass, \n",
    "                         name='KNN classification',\n",
    "                         line=dict(color='red'))) \n",
    "fig.add_trace(go.Scatter(x=[0,1], \n",
    "                         y=[0,1], \n",
    "                         name='No classifier',\n",
    "                         line=dict(color='black', \n",
    "                                   dash='dash'))) \n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title_text=\"False Positive Rate\"),\n",
    "    yaxis=dict(title_text=\"True Positive Rate\"))\n",
    " \n",
    "fig.show()</pre>\n",
    "</tt></blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "royalblue"
         },
         "name": "LDA",
         "type": "scatter",
         "x": [
          0,
          0.0196078431372549,
          1
         ],
         "y": [
          0,
          0.3103448275862069,
          1
         ]
        },
        {
         "line": {
          "color": "red"
         },
         "name": "KNN classification",
         "type": "scatter",
         "x": [
          0,
          0.11764705882352941,
          1
         ],
         "y": [
          0,
          0.1724137931034483,
          1
         ]
        },
        {
         "line": {
          "color": "black",
          "dash": "dash"
         },
         "name": "No classifier",
         "type": "scatter",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"eef49b07-fa4c-4612-9fd4-091684f96bc3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"eef49b07-fa4c-4612-9fd4-091684f96bc3\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'eef49b07-fa4c-4612-9fd4-091684f96bc3',\n",
       "                        [{\"line\": {\"color\": \"royalblue\"}, \"name\": \"LDA\", \"type\": \"scatter\", \"x\": [0.0, 0.0196078431372549, 1.0], \"y\": [0.0, 0.3103448275862069, 1.0]}, {\"line\": {\"color\": \"red\"}, \"name\": \"KNN classification\", \"type\": \"scatter\", \"x\": [0.0, 0.11764705882352941, 1.0], \"y\": [0.0, 0.1724137931034483, 1.0]}, {\"line\": {\"color\": \"black\", \"dash\": \"dash\"}, \"name\": \"No classifier\", \"type\": \"scatter\", \"x\": [0, 1], \"y\": [0, 1]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"title\": {\"text\": \"False Positive Rate\"}}, \"yaxis\": {\"title\": {\"text\": \"True Positive Rate\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('eef49b07-fa4c-4612-9fd4-091684f96bc3');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=fpr_lda, \n",
    "                         y=tpr_lda, \n",
    "                         name='LDA',\n",
    "                         line=dict(color='royalblue'))) \n",
    "fig.add_trace(go.Scatter(x=fpr_knnclass, \n",
    "                         y=tpr_knnclass, \n",
    "                         name='KNN classification',\n",
    "                         line=dict(color='red'))) \n",
    "fig.add_trace(go.Scatter(x=[0,1], \n",
    "                         y=[0,1], \n",
    "                         name='No classifier',\n",
    "                         line=dict(color='black', \n",
    "                                   dash='dash'))) \n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis=dict(title_text=\"False Positive Rate\"),\n",
    "    yaxis=dict(title_text=\"True Positive Rate\"))\n",
    " \n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
